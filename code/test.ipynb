{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"authorship_tag":"ABX9TyPX4auKz/HPeN4tadO4hSFg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FuMV8DUKEJJz","colab_type":"text"},"source":["**Test the trained model on N2C2 2018 Track 2 dataset. Compute F1 score.**"]},{"cell_type":"markdown","metadata":{"id":"5c14V-JRERt7","colab_type":"text"},"source":["Check-\n","1. tag accuracy for 'Reason' and 'ADE'\n","2. Inaccuracies in gold truth"]},{"cell_type":"code","metadata":{"id":"MLY4Xuf0EDy7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}