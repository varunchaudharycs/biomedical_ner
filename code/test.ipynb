{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNh1mD9WlNNisNpd2hwS+xC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yaa9cAjBnBjJ"},"source":["**Test the BioNER model on N2C2 2018 Track 2 dataset using trained Clinical-BERT. Save to /output**"]},{"cell_type":"markdown","metadata":{"id":"27nM9EWCvp7B"},"source":["# Initialize Parameters"]},{"cell_type":"code","metadata":{"id":"W4qZcOFazKU2","executionInfo":{"status":"ok","timestamp":1604004420620,"user_tz":420,"elapsed":102304,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"25303e22-4880-4d20-e5e2-96423b5dfbd2","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2qdBqWItzNQF","executionInfo":{"status":"ok","timestamp":1604004420626,"user_tz":420,"elapsed":102297,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["DATA_VER = \"v5\"\n","MODEL_VER = \"v9\"\n","PARENT_DIR = \"/content/gdrive/My Drive/projects/biomedical_ner\"\n","TEST_DIR = PARENT_DIR + \"/data/\" + DATA_VER + \"/test\"\n","MODEL_DIR = PARENT_DIR + \"/model/\" + MODEL_VER\n","OUTPUT_DIR = PARENT_DIR + \"/output/\" + MODEL_VER\n","\n","# MODEL_PATH = MODEL_DIR + \"/pytorch_model.bin\"\n","VOCAB_PATH = MODEL_DIR + \"/vocab.txt\"\n","CONFIG_PATH = MODEL_DIR + \"/config.json\"\n","PREDICTIONS_PATH = OUTPUT_DIR + \"/predictions.csv\"\n","REPORT_PATH = OUTPUT_DIR + \"/result.txt\"\n","CONFUSION_MATRIX_PATH = OUTPUT_DIR + \"/confusion_matrix.csv\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Wls5pvb0Bv1","executionInfo":{"status":"ok","timestamp":1604004421455,"user_tz":420,"elapsed":103118,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["import os\n","if not os.path.exists(OUTPUT_DIR):\n","  os.makedirs(OUTPUT_DIR)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"QGSTO1mSeXJQ","executionInfo":{"status":"ok","timestamp":1604004421459,"user_tz":420,"elapsed":103115,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["batch_size = 8\n","max_len = 384"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hw-Ttwsv0JLQ"},"source":["# Requirements Installation"]},{"cell_type":"code","metadata":{"id":"iECmqSjR0L1Y","executionInfo":{"status":"ok","timestamp":1604004431688,"user_tz":420,"elapsed":113337,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"4b580c53-ee73-4cf1-cf3a-093c9b16b67d","colab":{"base_uri":"https://localhost:8080/","height":867}},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","!pip install seqeval\n","!pip install transformers"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\r\u001b[K     |███████▌                        | 10kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=83dd0a8a5eed43cdf861046253c72b314cf885837000afc6cbeb4020942b88ce\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 9.6MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 43.0MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 56.9MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 41.1MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=b7c6ae30566be8a4d09b1eb9b7399623606e767db51c5e8ba61c19b19d339cd6\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B9-LtJ1i0H_c"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"O9ctAbjWe0pg","executionInfo":{"status":"ok","timestamp":1604004437414,"user_tz":420,"elapsed":119054,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["import pandas as pd\n","import math\n","import numpy as np\n","from seqeval.metrics import f1_score\n","from seqeval.metrics import classification_report,accuracy_score,f1_score\n","import torch.nn.functional as F\n","\n","import torch\n","import os\n","from tqdm import tqdm,trange\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader, SequentialSampler, Dataset, ConcatDataset\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer, BertTokenizer, BertForTokenClassification\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCu8LNaie8Ku","executionInfo":{"status":"ok","timestamp":1604004437672,"user_tz":420,"elapsed":119305,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"9037d529-e4d6-414d-83d9-5bf1736fd837","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# Check library version\n","!pip list | grep -E 'transformers|torch|Keras'"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Keras                         2.4.3          \n","Keras-Preprocessing           1.1.2          \n","torch                         1.6.0+cu101    \n","torchsummary                  1.5.1          \n","torchtext                     0.3.1          \n","torchvision                   0.7.0+cu101    \n","transformers                  3.4.0          \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IkHQ-u31fcQN"},"source":["# Setup Mapping"]},{"cell_type":"code","metadata":{"id":"qKttzOjFfekC","executionInfo":{"status":"ok","timestamp":1604004437673,"user_tz":420,"elapsed":119297,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["tag2idx = {'B-Drug': 0,\n","          'I-Drug': 1,\n","          'B-Reason': 2,\n","          'I-Reason': 3,\n","          'B-ADE': 4,\n","          'I-ADE': 5,\n","          'O': 6,\n","          'X': 7,\n","          '[CLS]': 8,\n","          '[SEP]': 9\n","          }\n","tag2name = {tag2idx[key] : key for key in tag2idx.keys()}"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aj9vz8Oyflxr"},"source":["# Setup GPU"]},{"cell_type":"code","metadata":{"id":"WyGVs6_Qfmvn","executionInfo":{"status":"ok","timestamp":1604004437674,"user_tz":420,"elapsed":119290,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"e6616ddc-5938-41c6-d6df-2ef59c9cb19b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","n_gpu"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"NYMzH2CF0W0i"},"source":["# Prepare Data"]},{"cell_type":"code","metadata":{"id":"_oLevWWwfrcY","executionInfo":{"status":"ok","timestamp":1604004439858,"user_tz":420,"elapsed":121460,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"b484f920-37d1-4a4c-9007-721bc5926500","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls '$TEST_DIR' | wc -l"],"execution_count":10,"outputs":[{"output_type":"stream","text":["202\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ub3QMZRZ0Ywy","executionInfo":{"status":"ok","timestamp":1604004439861,"user_tz":420,"elapsed":121452,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["class ClinicalDataset(Dataset):\n","    def __init__(self, file, path, max_seq_len, tag2idx, tokenizer):\n","        self.max_seq_len = max_seq_len;\n","        self.path = os.path.join(path, file)\n","        self.df = pd.read_csv(self.path, names=['patientID', 'sentenceID', 'token', 'tag'], keep_default_na=False)\n","        self.tag2idx = tag2idx\n","        self.tokenizer = tokenizer\n","        # Convert Tokens to indices\n","        self.prepare_data()\n","\n","    def prepare_data(self):\n","        sentences, labels = self.get_sentences(self.df)\n","        tokenized_texts, word_piece_labels = self.tokenize_text(sentences, labels)\n","\n","        # Make text token into id\n","        input_ids = pad_sequences([self.tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n","                                  maxlen=self.max_seq_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","        # Make label into id, pad with \"O\" meaning others/wrong\n","        tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n","                             maxlen=self.max_seq_len, value=self.tag2idx[\"X\"],\n","                             padding=\"post\", dtype=\"long\", truncating=\"post\")\n","\n","        # For fine tune of predict, with token mask is 1,pad token is 0\n","        attention_masks = [[int(i > 0) for i in ii] for ii in input_ids]\n","        \n","        self.Sentences = torch.tensor(input_ids)\n","        self.label_data = torch.tensor(tags)\n","        self.attention_masks = torch.tensor(attention_masks)\n","\n","    def get_sentences(self, data):\n","        agg_func = lambda s: [(w, t) for w, t in zip(s[\"token\"].values.tolist(), s[\"tag\"].values.tolist())]\n","        grouped = data.groupby(\"sentenceID\").apply(agg_func)\n","        tokenstags = [s for s in grouped]\n","        sentences = [[s[0] for s in sent] for sent in tokenstags]\n","        labels = [[s[1] for s in sent] for sent in tokenstags]\n","        return sentences, labels\n","\n","    def tokenize_text(self, sentences, labels):\n","        tokenized_texts = []\n","        word_piece_labels = []\n","        i_inc = 0\n","        for word_list, label in (zip(sentences,labels)):\n","            temp_label = []\n","            temp_token = []\n","\n","            # Add [CLS] at the front\n","            temp_label.append('[CLS]')\n","            temp_token.append('[CLS]')\n","\n","            for word,lab in zip(word_list,label):\n","                token_list = self.tokenizer.tokenize(word)\n","                for m,token in enumerate(token_list):\n","                    temp_token.append(token)\n","                    temp_label.append(lab)\n","\n","            # Add [SEP] at the end\n","            temp_token.append('[SEP]')\n","            temp_label.append('[SEP]')\n","\n","            tokenized_texts.append(temp_token)\n","            word_piece_labels.append(temp_label)\n","\n","        return tokenized_texts, word_piece_labels\n","\n","    def __len__(self):\n","        return len(self.Sentences)\n","\n","    def __getitem__(self, idx):\n","        return self.Sentences[idx], self.attention_masks[idx], self.label_data[idx]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IVgScy-fzkg","executionInfo":{"status":"ok","timestamp":1604004439861,"user_tz":420,"elapsed":121445,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"b3fb7b29-bee3-45ff-ff1a-674d1bec80be","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["VOCAB_PATH"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/gdrive/My Drive/projects/biomedical_ner/model/v9/vocab.txt'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Z-r5b_vif8tu","executionInfo":{"status":"error","timestamp":1604004440266,"user_tz":420,"elapsed":121838,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"522bd1ae-dda3-4109-c1a4-a8e73b9e7e56","colab":{"base_uri":"https://localhost:8080/","height":333}},"source":["# Tokenizer\n","tokenizer = BertTokenizer(vocab_file= VOCAB_PATH, do_lower_case=False)"],"execution_count":13,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-099be48c36fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mVOCAB_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m             raise ValueError(\n\u001b[1;32m    191\u001b[0m                 \u001b[0;34m\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;34m\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             )\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Can't find a vocabulary file at path '/content/gdrive/My Drive/projects/biomedical_ner/model/v9/vocab.txt'. To load the vocabulary from a Google pretrained model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`"]}]},{"cell_type":"code","metadata":{"id":"0YKD4oMVf_Bn","executionInfo":{"status":"aborted","timestamp":1604004440256,"user_tz":420,"elapsed":121819,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["# TEST DATASET\n","test_datasets = []\n","\n","for doc in os.listdir(TEST_DIR):\n","    test_datasets.append(ClinicalDataset(doc, TEST_DIR, max_len, tag2idx, tokenizer))\n","\n","# concatenate CSV data\n","test_dataset = ConcatDataset(test_datasets)\n","\n","test_sampler = SequentialSampler(test_dataset)\n","\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size,drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PTT0PLZ0Z9B"},"source":["# Load Model"]},{"cell_type":"code","metadata":{"id":"gGojUWFY4Zaf","executionInfo":{"status":"aborted","timestamp":1604004440257,"user_tz":420,"elapsed":121814,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["!ls '$MODEL_DIR'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8as9Y0_t0dPA","executionInfo":{"status":"aborted","timestamp":1604004440258,"user_tz":420,"elapsed":121807,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR, num_labels=len(tag2idx))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDWfR-660mPB","executionInfo":{"status":"aborted","timestamp":1604004440259,"user_tz":420,"elapsed":121801,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["model.cuda();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dewaogaU0qyz"},"source":["# Test Model(TODO)"]},{"cell_type":"code","metadata":{"id":"a2fHBcv00vZm","executionInfo":{"status":"aborted","timestamp":1604004440259,"user_tz":420,"elapsed":121793,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["model.eval();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8JQ9zDq0w6C","executionInfo":{"status":"aborted","timestamp":1604004440260,"user_tz":420,"elapsed":121787,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["y_true = []\n","y_pred = []\n","y_confidence = []\n","\n","probs = []\n","out = []\n","print(\"***** Running evaluation *****\")\n","print(\"  Num examples = {}\".format(len(test_dataset)))\n","print(\"  Batch size = {}\".format(batch_size))\n","for step, batch in enumerate(test_dataloader):\n","    batch = tuple(t.to(device) for t in batch)\n","    input_ids, input_mask, label_ids = batch\n","    \n","    with torch.no_grad():\n","        outputs = model(input_ids, token_type_ids=None,\n","        attention_mask=input_mask)\n","        # For eval mode, the first result of outputs is logits\n","        logits = outputs[0] \n","    \n","    # Model Confidence\n","    logits_prob, _ = torch.max(F.softmax(logits, dim=2),dim=2)\n","    logits_prob = logits_prob.detach().cpu().numpy()\n","\n","    # print(logits_prob)\n","    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n","    logits = logits.detach().cpu().numpy()\n","    \n","    # Get NER true result\n","    label_ids = label_ids.to('cpu').numpy()\n","    \n","    # Only predict the real word, mark=0, will not calculate\n","    input_mask = input_mask.to('cpu').numpy()\n","    \n","    # Compare the valuable predict result\n","    for i,mask in enumerate(input_mask):\n","        # Ground truth\n","        temp_true = []\n","        # Prediction\n","        temp_pred = []\n","\n","        temp_confidence = []\n","        for j, m in enumerate(mask):\n","            # Mark=0 (Label_ids = \"X\"), meaning its a pad word, dont compare\n","            if m:\n","                if tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\":\n","                    temp_true.append(tag2name[label_ids[i][j]])\n","                    temp_pred.append(tag2name[logits[i][j]])\n","                    temp_confidence.append(logits_prob[i][j])\n","                    # TODO: F1 Logic (Lenient)\n","                    # if tag2name[label_ids[i][j]] == \"C\" or tag2name[label_ids[i][j]] == \"W\":\n","                    #   out.append({\"Actual\":tag2name[label_ids[i][j]], \"Predicted\": tag2name[logits[i][j]], \"Confidence\": logits_prob[i][j]})\n","\n","            else:\n","                break\n","        \n","            \n","        y_true.append(temp_true)\n","        y_pred.append(temp_pred)\n","        y_confidence.append(temp_confidence)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YYX92Mxz04wQ"},"source":["# Predictions"]},{"cell_type":"code","metadata":{"id":"Z8QAaf__07T9","executionInfo":{"status":"aborted","timestamp":1604004440261,"user_tz":420,"elapsed":121778,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["result = pd.DataFrame()\n","result[\"actual\"] = y_true\n","result[\"predicted\"] = y_pred\n","result[\"confidence\"] = y_confidence\n","\n","result.to_csv(PREDICTIONS_PATH, sep=\",\", encoding=\"utf-8\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsqO_PL41LG9"},"source":["# Analysis"]},{"cell_type":"markdown","metadata":{"id":"JwTm-YCSqQqh"},"source":["**F1 Scores (Strict & Lenient)**"]},{"cell_type":"code","metadata":{"id":"27pxI7343AL7","executionInfo":{"status":"aborted","timestamp":1604004440262,"user_tz":420,"elapsed":121772,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["# Get acc , recall, F1 result report\n","report_lenient = classification_report(y_true, y_pred, zero_division=1, digits=4)\n","report_strict = classification_report(y_true, y_pred, mode='strict', zero_division=1, digits=4)\n","\n","# Save the report into file\n","with open(REPORT_PATH, \"w\") as writer:\n","    print(\"***** Eval results(Lenient) *****\")\n","    print(\"\\n%s\"%(report_lenient))\n","    print(\"F1 score: %f\"%(f1_score(y_true, y_pred,zero_division=1)))\n","    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n","    \n","    writer.write(\"F1 score(Lenient):\\n\")\n","    writer.write(str(f1_score(y_true, y_pred)))\n","    writer.write(\"\\n\\nAccuracy score:\\n\")\n","    writer.write(str(accuracy_score(y_true, y_pred)))\n","    writer.write(\"\\n\\n\")  \n","    writer.write(report_lenient)\n","\n","    print(\"***** Eval results(Strict) *****\")\n","    print(\"\\n%s\"%(report_strict))\n","    print(\"F1 score: %f\"%(f1_score(y_true, y_pred,zero_division=1, mode='strict')))\n","    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n","    \n","    writer.write(\"F1 score(Strict):\\n\")\n","    writer.write(str(f1_score(y_true, y_pred, mode='strict')))\n","    writer.write(\"\\n\\nAccuracy score:\\n\")\n","    writer.write(str(accuracy_score(y_true, y_pred)))\n","    writer.write(\"\\n\\n\")  \n","    writer.write(report_strict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qTa3J08X09Kr","executionInfo":{"status":"aborted","timestamp":1604004440262,"user_tz":420,"elapsed":121761,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["!ls '$OUTPUT_DIR'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_2ZelYU1Nv1","executionInfo":{"status":"aborted","timestamp":1604004440264,"user_tz":420,"elapsed":121752,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["result.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ujsjF7LeqWld"},"source":["**Confusion Matrix**"]},{"cell_type":"code","metadata":{"id":"eOnSpaV0lezt","executionInfo":{"status":"aborted","timestamp":1604004440265,"user_tz":420,"elapsed":121742,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["classes = ['ADE', 'Reason', 'Drug', 'O']\n","\n","def get_cleaned_label(label: str):\n","    if \"-\" in label:\n","        return label.split(\"-\")[1]\n","    else:\n","        return label\n","\n","y_true_total = [get_cleaned_label(item) for sublist in y_true for item in sublist]\n","y_pred_total = [get_cleaned_label(item) for sublist in y_pred for item in sublist]\n","\n","conf_matrix = confusion_matrix(y_true_total, y_pred_total, labels = classes)\n","conf_df = pd.DataFrame(data=conf_matrix,index=classes,columns=classes)\n","\n","conf_df.to_csv(CONFUSION_MATRIX_PATH, sep=\",\", encoding=\"utf-8\")\n","conf_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zK3Hy4NxsE33","executionInfo":{"status":"aborted","timestamp":1604004440265,"user_tz":420,"elapsed":121732,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}}},"source":["!ls '$OUTPUT_DIR'"],"execution_count":null,"outputs":[]}]}