{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c8cd5ea1ef6c4f7d9816d85da78e991a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c5722239f17e4fef949f42c95ebfbbcc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0351f1d03d194192afe4f73bb789b967","IPY_MODEL_6a1376ececdc4a0e891d9ab471e57c07"]}},"c5722239f17e4fef949f42c95ebfbbcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0351f1d03d194192afe4f73bb789b967":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eaf31cbc534148a49006eb3ceadfb6f8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":385,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":385,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a032f2981ee46bea8bdc4c4dfd61894"}},"6a1376ececdc4a0e891d9ab471e57c07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75c15e925d32490ba9f23a575de31215","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 385/385 [00:00&lt;00:00, 517B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f102e8c61de84a4197f71a6f71c1e6d5"}},"eaf31cbc534148a49006eb3ceadfb6f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5a032f2981ee46bea8bdc4c4dfd61894":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75c15e925d32490ba9f23a575de31215":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f102e8c61de84a4197f71a6f71c1e6d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d437b7f72dac442480fe1774d71cf2b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_31a72446fc6e487f80875b014e931888","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a2f46668499a41e69dffbaba2a4c3c00","IPY_MODEL_2722be545e374053b2bca84a538dc509"]}},"31a72446fc6e487f80875b014e931888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2f46668499a41e69dffbaba2a4c3c00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_09f9f31b06cb4eb28eea988e372a7f7a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97ea521991e7477b81ac9680b42491a0"}},"2722be545e374053b2bca84a538dc509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7c316a8f482241568da587d1ef1b6942","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 458kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f71a61eb7b234a32a4af92131ea72665"}},"09f9f31b06cb4eb28eea988e372a7f7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"97ea521991e7477b81ac9680b42491a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c316a8f482241568da587d1ef1b6942":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f71a61eb7b234a32a4af92131ea72665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"mb06wqbWDz5T"},"source":["**Train the BioNER model on N2C2 2018 Track 2 dataset using Clinical-BERT. Save to /model**"]},{"cell_type":"markdown","metadata":{"id":"z-XGajYbvv3l"},"source":["## Data\n","- v1 = Arbitrary 300-length input to model\n","    #### Models\n","    - v1 = ClinicalBERT with finetuning(with data v1) \"emilyalsentzer/Bio_ClinicalBERT\"\n","    - v2 = BioBERT with finetuning(with data v1) \"dmis-lab/biobert-v1.1\"\n","    - v3 = BERT with finetuning(with data v1)\n","    - v7 =  Bio_Discharge_Summary_BERT\n","    - v8 = Overlaps filtered data (Arbitrary 300-length input to model)"]},{"cell_type":"code","metadata":{"id":"QTI2X-1-DxOC"},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpHC6woGD0u7"},"source":["# Initialize Parameters\n"]},{"cell_type":"code","metadata":{"id":"pLGQEg6lDsBn","executionInfo":{"status":"ok","timestamp":1604027766789,"user_tz":420,"elapsed":19190,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"4291d897-e8f1-4821-b64c-c33716fb1919","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wd3An5XTZfK2","executionInfo":{"status":"ok","timestamp":1604027767236,"user_tz":420,"elapsed":19628,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"5443b132-1491-4887-da3f-404260eb6517","colab":{"base_uri":"https://localhost:8080/"}},"source":["!ls '/content/gdrive/My Drive/projects/biomedical_ner/model'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["v1  v2\tv3  v4\tv5  v7\tv8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZJr_sdXurZ2N"},"source":["DATA_VER = \"v1\"\n","MODEL_VER = \"v7\" \n","PARENT_DIR = \"/content/gdrive/My Drive/projects/biomedical_ner\"\n","DATA_DIR = PARENT_DIR + \"/data/\" + DATA_VER\n","MODEL_DIR = PARENT_DIR + \"/model/\" + MODEL_VER\n","TRAIN_DIR = DATA_DIR + \"/train\"\n","VAL_DIR = DATA_DIR + \"/val\"\n","OUTPUT_DIR = PARENT_DIR + \"/output/\" + MODEL_VER\n","\n","MODEL_PATH = MODEL_DIR + \"/pytorch_model.bin\"\n","CONFIG_PATH = MODEL_DIR + \"/config.json\"\n","VOCAB_PATH = MODEL_DIR + \"/vocab.txt\"\n","CLINICAL_BERT = \"emilyalsentzer/Bio_Discharge_Summary_BERT\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tmFO9OFobsa"},"source":["import os\n","if not os.path.exists(MODEL_DIR):\n","  os.makedirs(MODEL_DIR)\n","if not os.path.exists(OUTPUT_DIR):\n","  os.makedirs(OUTPUT_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k__ruTr0uGVQ"},"source":["batch_size = 8\n","max_len = 384\n","epochs = 8\n","max_grad_norm = 1.0\n","full_finetuning = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNqHhDGuFEPS"},"source":["# Requirements Installation"]},{"cell_type":"code","metadata":{"id":"1jxRJvt1EpOq","executionInfo":{"status":"ok","timestamp":1604027779914,"user_tz":420,"elapsed":32290,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"0b27dcf7-c049-4b08-d6e8-58dca93f08db","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install seqeval\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\r\u001b[K     |███████▌                        | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=5600a128c520d62d2f098b86731ac95cca7ad7a9283ee228f73f96517018ecd4\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 18.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 24.4MB/s \n","\u001b[?25hCollecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 27.9MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=f3e078f87ef8ba533e261e471fd67e13a22a4a9b987bef3f9ea6ca1c2f266b58\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aBAw3bkJFVjG"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"EkOFiy4KFSUw"},"source":["import pandas as pd\n","import math\n","import numpy as np\n","from seqeval.metrics import f1_score\n","from seqeval.metrics import classification_report,accuracy_score,f1_score\n","import torch.nn.functional as F\n","from torch.nn import CrossEntropyLoss\n","\n","import torch\n","import os\n","from tqdm import tqdm,trange\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader, SequentialSampler, Dataset, ConcatDataset\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer, AdamW, BertTokenizer, BertForTokenClassification\n","from transformers import get_linear_schedule_with_warmup\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0QUe5m3JFdS5","executionInfo":{"status":"ok","timestamp":1604027785716,"user_tz":420,"elapsed":38083,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"08c5a278-fa2e-4630-ca3b-cf6e11432052","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Check library version\n","!pip list | grep -E 'transformers|torch|Keras'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Keras                         2.4.3          \n","Keras-Preprocessing           1.1.2          \n","torch                         1.6.0+cu101    \n","torchsummary                  1.5.1          \n","torchtext                     0.3.1          \n","torchvision                   0.7.0+cu101    \n","transformers                  3.4.0          \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dLvXMrbD2dt9"},"source":["# Setup Mapping"]},{"cell_type":"code","metadata":{"id":"Gec00YIoxhYx"},"source":["tag2idx = {'B-Drug': 0,\n","          'I-Drug': 1,\n","          'B-Reason': 2,\n","          'I-Reason': 3,\n","          'B-ADE': 4,\n","          'I-ADE': 5,\n","          'O': 6,\n","          'X': 7,\n","          '[CLS]': 8,\n","          '[SEP]': 9\n","          }\n","tag2name = {tag2idx[key] : key for key in tag2idx}\n","class_weights = torch.tensor([3.919, 5.603, 5.40014, 5.53310, 6.83903, 6.943808, 1, 1, 1, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1e0wETSz0FrW"},"source":["# Setup GPU"]},{"cell_type":"code","metadata":{"id":"77XrTxBy0Hv4","executionInfo":{"status":"ok","timestamp":1604027785718,"user_tz":420,"elapsed":38078,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"49ae54f6-2366-4fcc-fc2c-c97100b017d4","colab":{"base_uri":"https://localhost:8080/"}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","n_gpu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"EGgXt6LwHIhf"},"source":["# Prepare Data- Load, Concatenate, Tokenize"]},{"cell_type":"code","metadata":{"id":"EwbXC16t5NEX","executionInfo":{"status":"ok","timestamp":1604027787419,"user_tz":420,"elapsed":39776,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"0820d060-2cd4-4db9-ce37-b936a6f58ec4","colab":{"base_uri":"https://localhost:8080/"}},"source":["!ls '$TRAIN_DIR' | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EPuNTMD3HHBa","executionInfo":{"status":"ok","timestamp":1604027787420,"user_tz":420,"elapsed":39773,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"212469da-2afb-4176-8ac7-3b289f09b5ab","colab":{"base_uri":"https://localhost:8080/"}},"source":["!ls '$VAL_DIR' | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["38\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8xS3mFM-7SZ"},"source":["class ClinicalDataset(Dataset):\n","    def __init__(self, file, path, max_seq_len, tag2idx, tokenizer):\n","        self.max_seq_len = max_seq_len;\n","        self.path = os.path.join(path, file)\n","        self.df = pd.read_csv(self.path, names=['patientID', 'sentenceID', 'token', 'tag'], keep_default_na=False)\n","        self.tag2idx = tag2idx\n","        self.tokenizer = tokenizer\n","        # Convert Tokens to indices\n","        self.prepare_data()\n","\n","    def prepare_data(self):\n","        sentences, labels = self.get_sentences(self.df)\n","        tokenized_texts, word_piece_labels = self.tokenize_text(sentences, labels)\n","\n","        # Make text token into id\n","        input_ids = pad_sequences([self.tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n","                                  maxlen=self.max_seq_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","        # Make label into id, pad with \"X\" meaning others/wrong\n","        tags = pad_sequences([[tag2idx[l] for l in lab] for lab in word_piece_labels],\n","                             maxlen=self.max_seq_len, value=self.tag2idx[\"X\"],\n","                             padding=\"post\", dtype=\"long\", truncating=\"post\")\n","\n","        # For fine tune of predict, with token mask is 1,pad token is 0\n","        attention_masks = [[int(i > 0) for i in ii] for ii in input_ids]\n","\n","        self.Sentences = torch.tensor(input_ids)\n","        self.label_data = torch.tensor(tags)\n","        self.attention_masks = torch.tensor(attention_masks)\n","\n","    def get_sentences(self, data):\n","        agg_func = lambda s: [(w, t) for w, t in zip(s[\"token\"].values.tolist(), s[\"tag\"].values.tolist())]\n","        grouped = data.groupby(\"sentenceID\").apply(agg_func)\n","        tokenstags = [s for s in grouped]\n","        sentences = [[s[0] for s in sent] for sent in tokenstags]\n","        labels = [[s[1] for s in sent] for sent in tokenstags]\n","        return sentences, labels\n","\n","    def tokenize_text(self, sentences, labels):\n","        tokenized_texts = []\n","        word_piece_labels = []\n","        i_inc = 0\n","        for word_list, label in (zip(sentences,labels)):\n","            temp_label = []\n","            temp_token = []\n","\n","            # Add [CLS] at the front\n","            temp_label.append('[CLS]')\n","            temp_token.append('[CLS]')\n","\n","            for word,lab in zip(word_list,label):\n","                token_list = self.tokenizer.tokenize(word)\n","                for m,token in enumerate(token_list):\n","                    temp_token.append(token)\n","                    temp_label.append(lab)\n","\n","            # Add [SEP] at the end\n","            temp_token.append('[SEP]')\n","            temp_label.append('[SEP]')\n","\n","            tokenized_texts.append(temp_token)\n","            word_piece_labels.append(temp_label)\n","\n","        return tokenized_texts, word_piece_labels\n","\n","    def __len__(self):\n","        return len(self.Sentences)\n","\n","    def __getitem__(self, idx):\n","        return self.Sentences[idx], self.attention_masks[idx], self.label_data[idx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNJyqP1Yeujw","executionInfo":{"status":"ok","timestamp":1604027788736,"user_tz":420,"elapsed":41083,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"a96c7dcf-f37f-4e8f-9116-b74d33fac002","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["c8cd5ea1ef6c4f7d9816d85da78e991a","c5722239f17e4fef949f42c95ebfbbcc","0351f1d03d194192afe4f73bb789b967","6a1376ececdc4a0e891d9ab471e57c07","eaf31cbc534148a49006eb3ceadfb6f8","5a032f2981ee46bea8bdc4c4dfd61894","75c15e925d32490ba9f23a575de31215","f102e8c61de84a4197f71a6f71c1e6d5","d437b7f72dac442480fe1774d71cf2b5","31a72446fc6e487f80875b014e931888","a2f46668499a41e69dffbaba2a4c3c00","2722be545e374053b2bca84a538dc509","09f9f31b06cb4eb28eea988e372a7f7a","97ea521991e7477b81ac9680b42491a0","7c316a8f482241568da587d1ef1b6942","f71a61eb7b234a32a4af92131ea72665"]}},"source":["# Tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(CLINICAL_BERT, do_lower_case=False)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8cd5ea1ef6c4f7d9816d85da78e991a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d437b7f72dac442480fe1774d71cf2b5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aKFz1RF3IE0X"},"source":["# TRAIN DATASET\n","train_datasets = []\n","\n","for doc in os.listdir(TRAIN_DIR):\n","    train_datasets.append(ClinicalDataset(doc, TRAIN_DIR, max_len, tag2idx, tokenizer))\n","\n","# concatenate CSV data\n","train_dataset = ConcatDataset(train_datasets)\n","\n","train_sampler = SequentialSampler(train_dataset)\n","\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size,drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VuzzPCwIzEb"},"source":["# VAL DATASET\n","val_datasets = []\n","\n","for doc in os.listdir(VAL_DIR):\n","    val_datasets.append(ClinicalDataset(doc, VAL_DIR, max_len, tag2idx, tokenizer))\n","\n","# concatenate CSV data\n","val_dataset = ConcatDataset(val_datasets)\n","\n","val_sampler = SequentialSampler(val_dataset)\n","\n","val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size,drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KUm_xsEIYvs_"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"KbBgzH-GYy_e"},"source":["config = AutoConfig.from_pretrained(CLINICAL_BERT, num_labels=len(tag2idx), finetuning_task=\"ClinicalNER\")\n","model = AutoModelForTokenClassification.from_config(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqbT8rQnZzBV","executionInfo":{"status":"error","timestamp":1604027887790,"user_tz":420,"elapsed":140124,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"4a319680-5702-4b2e-e9ac-15f71e1f8066","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.cuda();"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-cb7b895bb807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n\u001b[1;32m    189\u001b[0m                 \"libcudart functions unavailable. It looks like you have a broken build?\")\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:47"]}]},{"cell_type":"code","metadata":{"id":"-I3Ca8qFZ5gl"},"source":["if full_finetuning:\n","    # Fine tune model all layer parameters\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'gamma', 'beta']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.0}\n","    ]\n","else:\n","    # Only fine tune classifier parameters\n","    param_optimizer = list(model.classifier.named_parameters()) \n","    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xOWiowBA9zQ"},"source":["# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=total_steps\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHeDLn5giHnc"},"source":["num_train_optimization_steps = int( math.ceil(len(train_dataset) / batch_size) / 1) * epochs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzicQ6jAaMpZ"},"source":["print(\"***** Running training *****\")\n","print(\"  Num examples = %d\"%(len(train_dataset)))\n","print(\"  Batch size = %d\"%(batch_size))\n","print(\"  Num steps = %d\"%(num_train_optimization_steps))\n","loss_values, validation_loss_values = [], []\n","for _ in trange(epochs,desc=\"Epoch\"):\n","    model.train();\n","    tr_loss = 0\n","    nb_tr_examples = 0\n","    for step, batch in enumerate(train_dataloader):\n","        # add batch to gpu\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # forward pass\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels = b_labels)\n","        loss = outputs[0]\n","\n","        # backward pass\n","        loss.backward()\n","        \n","        # track train loss\n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n","        \n","        # update parameters\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        \n","\n","    # print and store train loss\n","    train_loss = (tr_loss / nb_tr_examples)\n","    loss_values.append(train_loss)\n","    print(\"Train loss: {}\".format(train_loss))\n","\n","    # VALIDATION STEP\n","    model.eval();\n","    val_loss = 0\n","    nb_eval_examples = 0\n","    predictions , true_labels = [], []\n","\n","    for batch in val_dataloader:\n","        # add batch to gpu\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        with torch.no_grad():\n","          # forward pass\n","          outputs = model(b_input_ids, token_type_ids=None,\n","          attention_mask=b_input_mask, labels=b_labels)\n","\n","        # Move logits and labels to CPU\n","        logits = outputs[1].detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the loss for this batch of test sentences.\n","        val_loss += outputs[0].item()\n","        nb_eval_examples += b_input_ids.size(0)\n","        \n","        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","        true_labels.extend(label_ids)\n","        \n","    eval_loss = (val_loss / nb_eval_examples)\n","    validation_loss_values.append(eval_loss)\n","    print(\"Validation loss: {}\".format(eval_loss))\n","\n","    pred_tags = [[tag2name[p_i] for p_i, l_i in zip(p, l) if (tag2name[l_i] != \"X\" and tag2name[l_i] != \"[CLS]\" and tag2name[l_i] != \"[SEP]\")] for p, l in zip(predictions, true_labels)]\n","    valid_tags = [[tag2name[l_i] for l_i in l if (tag2name[l_i] != \"X\" and tag2name[l_i] != \"[CLS]\" and tag2name[l_i] != \"[SEP]\")] for l in true_labels]\n","\n","    report = classification_report(valid_tags, pred_tags,digits=4)\n","    print(\"***** Eval results *****\")\n","    print(\"\\n%s\"%(report))\n","    print(\"F1 score: %f\"%(f1_score(valid_tags, pred_tags)))\n","    print(\"Accuracy score: %f\"%(accuracy_score(valid_tags, pred_tags)))\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nZvoNtC3acIb"},"source":["# Save Model"]},{"cell_type":"code","metadata":{"id":"AH5_wTgjaQwF"},"source":["savemodel = model.module if hasattr(model, 'module') else model\n","\n","torch.save(savemodel.state_dict(), MODEL_PATH)\n","savemodel.config.to_json_file(CONFIG_PATH)\n","tokenizer.save_vocabulary(MODEL_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5w03pomr21Xc"},"source":["!ls '$MODEL_DIR'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"drERJcpqF4O2"},"source":["# Analyse"]},{"cell_type":"code","metadata":{"id":"pGTkbHYrFPIj"},"source":["# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(loss_values, 'b-o', label=\"training loss\")\n","plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n","\n","# Label the plot.\n","plt.title(\"Learning curve\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","\n","plt.savefig(OUTPUT_DIR + \"/loss.png\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWlQEulT35ch"},"source":["!ls '$OUTPUT_DIR'"],"execution_count":null,"outputs":[]}]}