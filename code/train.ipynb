{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"37a411047f73457691dac69e0ddbcd52":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4cd69b15f3394f6489eb4cc38ae622c9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_780448a19d6d4b47bd3b5e7aed1ccaf3","IPY_MODEL_e7288fc32fbf4a4b9b16f9880a0233c7"]}},"4cd69b15f3394f6489eb4cc38ae622c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"780448a19d6d4b47bd3b5e7aed1ccaf3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_82bddd43bc6f4ddcb2aed9c74c6ae3d0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":385,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":385,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98c0e5f66b074c9998d18c593de05cc9"}},"e7288fc32fbf4a4b9b16f9880a0233c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ec19a2563ffd4039b1de60d6d1bc5c55","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 385/385 [00:00&lt;00:00, 632B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7345d61528154c35b2a3af24f821fd8f"}},"82bddd43bc6f4ddcb2aed9c74c6ae3d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"98c0e5f66b074c9998d18c593de05cc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec19a2563ffd4039b1de60d6d1bc5c55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7345d61528154c35b2a3af24f821fd8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"605fde83a8e54cb8979c62925cf36e0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_052ccb4bdcb648e1a28b888f0f589661","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_52a150d30b844b55813571de83fdab56","IPY_MODEL_3dfb09a862c743b589feaa2563b8592d"]}},"052ccb4bdcb648e1a28b888f0f589661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52a150d30b844b55813571de83fdab56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba66b550adef43408b60b8e6571d93d7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_adccbf130925417f8e4a9937a687eb91"}},"3dfb09a862c743b589feaa2563b8592d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d2f7515a1234e98bc1eddd565e42a46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 526kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3fbd3e9cc56e4b63a0ee0f1fefc7ea70"}},"ba66b550adef43408b60b8e6571d93d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"adccbf130925417f8e4a9937a687eb91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d2f7515a1234e98bc1eddd565e42a46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3fbd3e9cc56e4b63a0ee0f1fefc7ea70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"mb06wqbWDz5T"},"source":["**Train the BioNER model on N2C2 2018 Track 2 dataset using Clinical-BERT. Save to /model**"]},{"cell_type":"markdown","metadata":{"id":"s2CZREF7MmZQ"},"source":["**Chosen as BERT baseline**\n","**BERT-CRF final model performed better**"]},{"cell_type":"markdown","metadata":{"id":"z-XGajYbvv3l"},"source":["**Data versions**\n","- v1 = Sentence-level input + Overlap filtering + max seq len(~192)\n","- (BEST)v2 = reduced max seq length to ~100\n","\n","**Model versions**\n","- v1 = Bio_Discharge_Summary_BERT(data=v1)\n","- v2 = Bio_Discharge_Summary_BERT(data=v1) trained with weights, scheduler\n","- v3 = reduced max seq length 128 , 150 epoch, 16 batch, 2e-5 lr(val= 70)\n","- (BEST)v4 = reduced max seq length 128 , 150 epoch, 32 batch, 3e-5 lr, dropout = 0.1(val= 70)\n","\n","Note- max seq length ~350 (Stopped as the f1 was 0.40 at 80th epoch, because much info was scrapped after word pieces took total length over max seq length)\n"]},{"cell_type":"code","metadata":{"id":"QTI2X-1-DxOC"},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpHC6woGD0u7"},"source":["# Initialize Parameters\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLGQEg6lDsBn","executionInfo":{"status":"ok","timestamp":1606419892689,"user_tz":420,"elapsed":22924,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"bec364b8-1452-4896-99f9-c0fd90fd6a55"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wd3An5XTZfK2","executionInfo":{"status":"ok","timestamp":1606419893089,"user_tz":420,"elapsed":23318,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"c9cd2ce1-9f6e-464a-ed5e-bbc805f4fa3d"},"source":["!ls '/content/gdrive/My Drive/projects/biomedical_ner/model'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["v1  v3\tv4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZJr_sdXurZ2N"},"source":["DATA_VER = \"v2\"\n","MODEL_VER = \"v4\"\n","PARENT_DIR = \"/content/gdrive/My Drive/projects/biomedical_ner\"\n","DATA_DIR = PARENT_DIR + \"/data/\" + DATA_VER\n","MODEL_DIR = PARENT_DIR + \"/model/\" + MODEL_VER\n","TRAIN_DIR = DATA_DIR + \"/train\"\n","VAL_DIR = DATA_DIR + \"/val\"\n","OUTPUT_DIR = PARENT_DIR + \"/output/\" + MODEL_VER\n","\n","MODEL_PATH = MODEL_DIR + \"/pytorch_model.bin\"\n","CONFIG_PATH = MODEL_DIR + \"/config.json\"\n","VOCAB_PATH = MODEL_DIR + \"/vocab.txt\"\n","BERT_VARIANT = \"emilyalsentzer/Bio_Discharge_Summary_BERT\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tmFO9OFobsa"},"source":["import os\n","if not os.path.exists(MODEL_DIR):\n","  os.makedirs(MODEL_DIR)\n","if not os.path.exists(OUTPUT_DIR):\n","  os.makedirs(OUTPUT_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k__ruTr0uGVQ"},"source":["batch_size = 16\n","max_len = 272 # tried 384\n","epochs = 100\n","lr = 3e-5\n","pad_label = \"X\"\n","max_grad_norm = 1.0\n","full_finetuning = True\n","dropout = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNqHhDGuFEPS"},"source":["# Requirements Installation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jxRJvt1EpOq","executionInfo":{"status":"ok","timestamp":1606419903222,"user_tz":420,"elapsed":33430,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"2283fa23-c6fe-4a3d-bb8b-cb435fd9e2f3"},"source":["!pip install seqeval\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\r\u001b[K     |███████▌                        | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 30.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 36.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 34.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=daa7106640a393197838a1cc60ce8db2da897d724072cf83d616b952487d510c\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 13.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 53.1MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 46.4MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 47.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=caa7f383850c14aa104078c57b9a39060e60bfea1cf7fdc965d4f959aabfb591\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EkOFiy4KFSUw"},"source":["import pandas as pd\n","import math\n","import numpy as np\n","from seqeval.metrics import f1_score\n","from seqeval.metrics import classification_report,accuracy_score,f1_score\n","import torch.nn.functional as F\n","from torch.nn import CrossEntropyLoss\n","\n","import torch\n","import os\n","from tqdm import tqdm,trange\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader, SequentialSampler, Dataset, ConcatDataset\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer, AdamW, BertTokenizer, BertForTokenClassification\n","from transformers import get_linear_schedule_with_warmup\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QUe5m3JFdS5","executionInfo":{"status":"ok","timestamp":1606419909895,"user_tz":420,"elapsed":40095,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"43f255b7-30f5-43c7-def4-418d9b074bcd"},"source":["# Check library version\n","!pip list | grep -E 'transformers|torch|Keras'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Keras                         2.4.3          \n","Keras-Preprocessing           1.1.2          \n","torch                         1.7.0+cu101    \n","torchsummary                  1.5.1          \n","torchtext                     0.3.1          \n","torchvision                   0.8.1+cu101    \n","transformers                  3.5.1          \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dLvXMrbD2dt9"},"source":["# Setup Mapping"]},{"cell_type":"code","metadata":{"id":"Gec00YIoxhYx"},"source":["tag2idx = {'B-Drug': 0,\n","          'I-Drug': 1,\n","          'B-Reason': 2,\n","          'I-Reason': 3,\n","          'B-ADE': 4,\n","          'I-ADE': 5,\n","          'O': 6,\n","          'X': 7,\n","          '[CLS]': 8,\n","          '[SEP]': 9\n","          }\n","tag2name = {tag2idx[key] : key for key in tag2idx}\n","# class_weights = torch.tensor([5.667039548812603, 30.35792759051186, 24.878964599959076, 28.26208740120874, 99.69946699466995, 116.96344396344396, 0.11770158405624111, 0, 9.980995772277634, 9.980995772277634])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1e0wETSz0FrW"},"source":["# Setup GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77XrTxBy0Hv4","executionInfo":{"status":"ok","timestamp":1606419909899,"user_tz":420,"elapsed":40093,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"6a64e265-c247-4d58-ddaa-e427c7e3a889"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","n_gpu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"EGgXt6LwHIhf"},"source":["# Prepare Data- Load, Concatenate, Tokenize"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwbXC16t5NEX","executionInfo":{"status":"ok","timestamp":1606419912550,"user_tz":420,"elapsed":42741,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"43e412c5-a078-4465-b1d4-8496ae36f54b"},"source":["!ls '$TRAIN_DIR' | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPuNTMD3HHBa","executionInfo":{"status":"ok","timestamp":1606419912551,"user_tz":420,"elapsed":42739,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"787ce5f5-dce0-45d4-ad39-87874072e28c"},"source":["!ls '$VAL_DIR' | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["38\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8xS3mFM-7SZ"},"source":["class ClinicalDataset(Dataset):\n","    def __init__(self, file, path, max_seq_len, tag2idx, tokenizer):\n","        self.max_seq_len = max_seq_len;\n","        self.path = os.path.join(path, file)\n","        self.df = pd.read_csv(self.path, names=['patientID', 'sentenceID', 'token', 'tag'], keep_default_na=False)\n","        self.tag2idx = tag2idx\n","        self.tokenizer = tokenizer\n","        # Convert Tokens to indices\n","        self.prepare_data()\n","\n","    def prepare_data(self):\n","        sentences, labels = self.get_sentences(self.df)\n","        tokenized_texts, word_piece_labels = self.tokenize_text(sentences, labels)\n","        # print(tokenized_texts)\n","        # print(word_piece_labels)\n","\n","        # Make text token into id\n","        input_ids = pad_sequences([self.tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n","                                  maxlen=self.max_seq_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","        # Make label into id, pad with \"X\" meaning others/wrong\n","        tags = pad_sequences([[tag2idx[l] for l in lab] for lab in word_piece_labels],\n","                             maxlen=self.max_seq_len, value=self.tag2idx[pad_label],\n","                             padding=\"post\", dtype=\"long\", truncating=\"post\")\n","\n","        # For fine tune of predict, with token mask is 1,pad token is 0\n","        attention_masks = [[int(i > 0) for i in ii] for ii in input_ids]\n","\n","        self.Sentences = torch.tensor(input_ids)\n","        self.label_data = torch.tensor(tags)\n","        self.attention_masks = torch.tensor(attention_masks)\n","\n","    def get_sentences(self, data):\n","        agg_func = lambda s: [(w, t) for w, t in zip(s[\"token\"].values.tolist(), s[\"tag\"].values.tolist())]\n","        grouped = data.groupby(\"sentenceID\").apply(agg_func)\n","        tokenstags = [s for s in grouped]\n","        sentences = [[s[0] for s in sent] for sent in tokenstags]\n","        labels = [[s[1] for s in sent] for sent in tokenstags]\n","        return sentences, labels\n","\n","    def tokenize_text(self, sentences, labels):\n","        tokenized_texts = []\n","        word_piece_labels = []\n","        i_inc = 0\n","        for word_list, label in (zip(sentences,labels)):\n","            temp_label = []\n","            temp_token = []\n","\n","            # Add [CLS] at the front\n","            temp_label.append('[CLS]')\n","            temp_token.append('[CLS]')\n","\n","            for word,lab in zip(word_list,label):\n","                token_list = self.tokenizer.tokenize(word)\n","                for m,token in enumerate(token_list):\n","                    temp_token.append(token)\n","                    if lab.startswith('B'):\n","                        if m==0:\n","                            temp_label.append(lab)\n","                        else:\n","                            temp_label.append('I-'+lab.split('-')[1])\n","                    else:\n","                        temp_label.append(lab)\n","\n","            # Add [SEP] at the end\n","            temp_token.append('[SEP]')\n","            temp_label.append('[SEP]')\n","\n","            tokenized_texts.append(temp_token)\n","            word_piece_labels.append(temp_label)\n","\n","        return tokenized_texts, word_piece_labels\n","\n","    def __len__(self):\n","        return len(self.Sentences)\n","\n","    def __getitem__(self, idx):\n","        return self.Sentences[idx], self.attention_masks[idx], self.label_data[idx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNJyqP1Yeujw","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["37a411047f73457691dac69e0ddbcd52","4cd69b15f3394f6489eb4cc38ae622c9","780448a19d6d4b47bd3b5e7aed1ccaf3","e7288fc32fbf4a4b9b16f9880a0233c7","82bddd43bc6f4ddcb2aed9c74c6ae3d0","98c0e5f66b074c9998d18c593de05cc9","ec19a2563ffd4039b1de60d6d1bc5c55","7345d61528154c35b2a3af24f821fd8f","605fde83a8e54cb8979c62925cf36e0f","052ccb4bdcb648e1a28b888f0f589661","52a150d30b844b55813571de83fdab56","3dfb09a862c743b589feaa2563b8592d","ba66b550adef43408b60b8e6571d93d7","adccbf130925417f8e4a9937a687eb91","4d2f7515a1234e98bc1eddd565e42a46","3fbd3e9cc56e4b63a0ee0f1fefc7ea70"]},"executionInfo":{"status":"ok","timestamp":1606419913350,"user_tz":420,"elapsed":43532,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"6c7defaa-275d-4f43-dc1b-e588e7f3aa74"},"source":["# Tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(BERT_VARIANT)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37a411047f73457691dac69e0ddbcd52","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"605fde83a8e54cb8979c62925cf36e0f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aKFz1RF3IE0X"},"source":["# TRAIN DATASET\n","train_datasets = []\n","\n","for doc in os.listdir(TRAIN_DIR):\n","    train_datasets.append(ClinicalDataset(doc, TRAIN_DIR, max_len, tag2idx, tokenizer))\n","\n","# concatenate CSV data\n","train_dataset = ConcatDataset(train_datasets)\n","\n","train_sampler = SequentialSampler(train_dataset)\n","\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size) # drop_last=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0SQq_3z_rrhE","executionInfo":{"status":"ok","timestamp":1606420010261,"user_tz":420,"elapsed":140438,"user":{"displayName":"Varun Chaudhary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOYdvyQdtVTBiRidViRirXqM80jHiqSoTSu7Ca=s64","userId":"08023458960254773878"}},"outputId":"b072c9d8-aece-4b8c-d5b2-d9abff12bd68"},"source":["print(f'Dataset length - {len(train_dataset)}, Dataloader length - {len(train_dataloader)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset length - 8121, Dataloader length - 508\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4VuzzPCwIzEb"},"source":["# VAL DATASET\n","val_datasets = []\n","\n","for doc in os.listdir(VAL_DIR):\n","    val_datasets.append(ClinicalDataset(doc, VAL_DIR, max_len, tag2idx, tokenizer))\n","\n","# concatenate CSV data\n","val_dataset = ConcatDataset(val_datasets)\n","\n","val_sampler = SequentialSampler(val_dataset)\n","\n","val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KUm_xsEIYvs_"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"KbBgzH-GYy_e"},"source":["config = AutoConfig.from_pretrained(BERT_VARIANT, num_labels=len(tag2idx), hidden_dropout_prob=dropout, finetuning_task=\"ClinicalNER\")\n","model = AutoModelForTokenClassification.from_config(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqbT8rQnZzBV"},"source":["model.cuda();\n","# loss_weights = torch.FloatTensor(class_weights).cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-I3Ca8qFZ5gl"},"source":["if full_finetuning:\n","    # Fine tune model all layer parameters\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'gamma', 'beta']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.0}\n","    ]\n","else:\n","    # Only fine tune classifier parameters\n","    param_optimizer = list(model.classifier.named_parameters()) \n","    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=1e-8) # (default=1e-6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xOWiowBA9zQ"},"source":["# Scheduler\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataset) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=total_steps\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzicQ6jAaMpZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"19251f82-5d6a-4cc8-cc3d-b28a09d84885"},"source":["print(\"\\n***** Running training *****\")\n","print(\"  Num examples = %d\"%(len(train_dataset)))\n","print(\"  Batch size = %d\"%(batch_size))\n","loss_values, val_loss_values = [], []\n","best_f1 = float(\"-inf\")\n","invalid_tags = set([\"X\", \"[CLS]\", \"[SEP]\"])\n","for _ in trange(epochs,desc=\"Epoch\"):\n","    model.train();\n","    tr_loss = 0\n","    # nb_tr_examples = 0\n","    for step, batch in enumerate(train_dataloader):\n","        # add batch to gpu\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # clear any previously calculated gradients\n","        model.zero_grad()\n","\n","        # forward pass\n","        outputs = model(b_input_ids, token_type_ids=None, \n","                        attention_mask=b_input_mask, labels = b_labels)\n","        loss = outputs[0]\n","        \n","\n","        # Custom loss calculation\n","        # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels = None)\n","        # logits = outputs[0]\n","        # loss = None\n","        # attention_mask = b_input_mask\n","        # labels = b_labels\n","\n","        # loss_fct = CrossEntropyLoss(weight=loss_weights)\n","        # if attention_mask is not None:\n","        #     active_loss = attention_mask.view(-1) == 1\n","        #     active_logits = logits.view(-1, len(tag2idx))\n","        #     active_labels = torch.where(active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels))\n","        #     loss = loss_fct(active_logits, active_labels)\n","        # else:\n","        #     loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        # backward pass\n","        loss.backward()\n","        \n","        # track train loss\n","        tr_loss += loss.item()\n","        # nb_tr_examples += b_input_ids.size(0)\n","        \n","        # Clip the norm of the gradient\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n","        \n","        # update parameters\n","        optimizer.step()\n","        scheduler.step()\n","        \n","\n","    # print and store train loss\n","    train_loss = (tr_loss / len(train_dataset))\n","    loss_values.append(train_loss)\n","    print(\"Train loss: {}\".format(train_loss))\n","\n","    # VALIDATION STEP\n","    model.eval();\n","    val_loss = 0\n","    # nb_eval_examples = 0\n","    predictions , true_labels = [], []\n","\n","    for batch in val_dataloader:\n","        # add batch to gpu\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        with torch.no_grad():\n","          # forward pass\n","          outputs = model(b_input_ids, token_type_ids=None,\n","          attention_mask=b_input_mask, labels=b_labels)\n","\n","        # Move logits and labels to CPU\n","        logits = outputs[1].detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the loss for this batch of test sentences.\n","        val_loss += outputs[0].item()\n","        # nb_eval_examples += b_input_ids.size(0)\n","        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","        true_labels.extend(label_ids)\n","        \n","    eval_loss = (val_loss / len(val_dataset))\n","    val_loss_values.append(eval_loss)\n","    print(\"Validation loss: {}\".format(eval_loss))\n","\n","    # pred_tags = [[tag2name[p_i] for p_i, l_i in zip(p, l) if (tag2name[l_i] != \"X\" and tag2name[l_i] != \"[CLS]\" and tag2name[l_i] != \"[SEP]\")] for p, l in zip(predictions, true_labels)]\n","    pred_tags = [[tag2name[p_i] for p_i, l_i in zip(p, l) if tag2name[l_i] not in invalid_tags] for p, l in zip(predictions, true_labels)]\n","    # valid_tags = [[tag2name[l_i] for l_i in l if (tag2name[l_i] != \"X\" and tag2name[l_i] != \"[CLS]\" and tag2name[l_i] != \"[SEP]\")] for l in true_labels]\n","    valid_tags = [[tag2name[l_i] for l_i in l if tag2name[l_i] not in invalid_tags] for l in true_labels]\n","\n","    report = classification_report(valid_tags, pred_tags,digits=4)\n","    print(\"***** Eval results *****\")\n","    print(\"\\n%s\"%(report))\n","    f1 = f1_score(valid_tags, pred_tags)\n","    print(\"F1 score: %f\"%(f1))\n","    print(\"Accuracy score: %f\"%(accuracy_score(valid_tags, pred_tags)))\n","\n","    # SAVE MODEL\n","    if f1 > best_f1:\n","      best_f1 = f1\n","      print('Saving model for BEST f1 - ', best_f1)\n","      savemodel = model.module if hasattr(model, 'module') else model\n","      torch.save(savemodel.state_dict(), MODEL_PATH)\n","      savemodel.config.to_json_file(CONFIG_PATH)\n","      tokenizer.save_vocabulary(MODEL_DIR)\n","    \n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/100 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","***** Running training *****\n","  Num examples = 8121\n","  Batch size = 16\n","Train loss: 0.013464989623837215\n","Validation loss: 0.00861716721204771\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0000    0.0000    0.0000       103\n","        Drug     0.2021    0.3084    0.2441      2043\n","      Reason     0.2060    0.1230    0.1541       447\n","\n","   micro avg     0.2024    0.2642    0.2292      2593\n","   macro avg     0.1360    0.1438    0.1327      2593\n","weighted avg     0.1947    0.2642    0.2189      2593\n","\n","F1 score: 0.229174\n","Accuracy score: 0.961824\n","Saving model for BEST f1 -  0.22917363666778187\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   1%|          | 1/100 [07:04<11:41:12, 424.97s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.009158228743800626\n","Validation loss: 0.008042696476096851\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0000    0.0000    0.0000       103\n","        Drug     0.2043    0.3514    0.2584      2043\n","      Reason     0.2520    0.1409    0.1808       447\n","\n","   micro avg     0.2074    0.3012    0.2457      2593\n","   macro avg     0.1521    0.1641    0.1464      2593\n","weighted avg     0.2044    0.3012    0.2347      2593\n","\n","F1 score: 0.245675\n","Accuracy score: 0.963138\n","Saving model for BEST f1 -  0.24567474048442905\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   2%|▏         | 2/100 [14:10<11:34:34, 425.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.008206785914529193\n","Validation loss: 0.007837432802793512\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0000    0.0000    0.0000       103\n","        Drug     0.2356    0.4356    0.3058      2043\n","      Reason     0.2574    0.1365    0.1784       447\n","\n","   micro avg     0.2369    0.3668    0.2879      2593\n","   macro avg     0.1643    0.1907    0.1614      2593\n","weighted avg     0.2300    0.3668    0.2717      2593\n","\n","F1 score: 0.287876\n","Accuracy score: 0.963358\n","Saving model for BEST f1 -  0.28787649462691084\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   3%|▎         | 3/100 [21:15<11:27:20, 425.16s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.007626741156881115\n","Validation loss: 0.007912627666605889\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.2000    0.0097    0.0185       103\n","        Drug     0.2387    0.4821    0.3193      2043\n","      Reason     0.1870    0.1477    0.1650       447\n","\n","   micro avg     0.2346    0.4057    0.2973      2593\n","   macro avg     0.2086    0.2132    0.1676      2593\n","weighted avg     0.2283    0.4057    0.2808      2593\n","\n","F1 score: 0.297301\n","Accuracy score: 0.962147\n","Saving model for BEST f1 -  0.29730111629221423\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   4%|▍         | 4/100 [28:21<11:20:22, 425.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.007144841066253119\n","Validation loss: 0.008119916241621294\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0625    0.0097    0.0168       103\n","        Drug     0.2447    0.5443    0.3376      2043\n","      Reason     0.1865    0.1611    0.1729       447\n","\n","   micro avg     0.2395    0.4570    0.3143      2593\n","   macro avg     0.1646    0.2384    0.1758      2593\n","weighted avg     0.2274    0.4570    0.2964      2593\n","\n","F1 score: 0.314324\n","Accuracy score: 0.960367\n","Saving model for BEST f1 -  0.31432360742705573\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   5%|▌         | 5/100 [35:26<11:13:16, 425.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.006643779838149843\n","Validation loss: 0.008999924229220345\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0282    0.0194    0.0230       103\n","        Drug     0.2467    0.6779    0.3617      2043\n","      Reason     0.1167    0.1767    0.1406       447\n","\n","   micro avg     0.2304    0.5654    0.3274      2593\n","   macro avg     0.1305    0.2914    0.1751      2593\n","weighted avg     0.2156    0.5654    0.3101      2593\n","\n","F1 score: 0.327378\n","Accuracy score: 0.954073\n","Saving model for BEST f1 -  0.32737829388119694\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   6%|▌         | 6/100 [42:31<11:05:54, 425.05s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.006016246355598804\n","Validation loss: 0.007906227575286667\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0208    0.0097    0.0132       103\n","        Drug     0.3069    0.6642    0.4198      2043\n","      Reason     0.1129    0.1879    0.1411       447\n","\n","   micro avg     0.2766    0.5561    0.3694      2593\n","   macro avg     0.1469    0.2873    0.1914      2593\n","weighted avg     0.2621    0.5561    0.3556      2593\n","\n","F1 score: 0.369412\n","Accuracy score: 0.962057\n","Saving model for BEST f1 -  0.36941206609453053\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   7%|▋         | 7/100 [49:35<10:58:37, 424.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.005330377207711801\n","Validation loss: 0.007448857544988064\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0235    0.0194    0.0213       103\n","        Drug     0.3421    0.6662    0.4521      2043\n","      Reason     0.1118    0.2103    0.1460       447\n","\n","   micro avg     0.2971    0.5619    0.3887      2593\n","   macro avg     0.1591    0.2986    0.2064      2593\n","weighted avg     0.2898    0.5619    0.3822      2593\n","\n","F1 score: 0.388689\n","Accuracy score: 0.964802\n","Saving model for BEST f1 -  0.3886888088568761\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   8%|▊         | 8/100 [56:39<10:51:08, 424.66s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.004750108472069903\n","Validation loss: 0.006677878139705265\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0417    0.0388    0.0402       103\n","        Drug     0.4398    0.6334    0.5192      2043\n","      Reason     0.1693    0.1924    0.1801       447\n","\n","   micro avg     0.3903    0.5337    0.4509      2593\n","   macro avg     0.2169    0.2882    0.2465      2593\n","weighted avg     0.3774    0.5337    0.4417      2593\n","\n","F1 score: 0.450888\n","Accuracy score: 0.971666\n","Saving model for BEST f1 -  0.4508877667372536\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:   9%|▉         | 9/100 [1:03:43<10:43:41, 424.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.004176493647215246\n","Validation loss: 0.006703661096748461\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0980    0.0971    0.0976       103\n","        Drug     0.4849    0.6750    0.5644      2043\n","      Reason     0.1600    0.2148    0.1834       447\n","\n","   micro avg     0.4188    0.5727    0.4838      2593\n","   macro avg     0.2476    0.3289    0.2818      2593\n","weighted avg     0.4135    0.5727    0.4801      2593\n","\n","F1 score: 0.483792\n","Accuracy score: 0.972397\n","Saving model for BEST f1 -  0.48379214855839714\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  10%|█         | 10/100 [1:10:48<10:36:40, 424.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.0034619544427029604\n","Validation loss: 0.006775490479087207\n","***** Eval results *****\n","\n","              precision    recall  f1-score   support\n","\n","         ADE     0.0504    0.0680    0.0579       103\n","        Drug     0.5248    0.7053    0.6018      2043\n","      Reason     0.1367    0.2841    0.1846       447\n","\n","   micro avg     0.4130    0.6074    0.4916      2593\n","   macro avg     0.2373    0.3525    0.2814      2593\n","weighted avg     0.4390    0.6074    0.5083      2593\n","\n","F1 score: 0.491650\n","Accuracy score: 0.971303\n","Saving model for BEST f1 -  0.4916497580771032\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uNLi9jSCECzv"},"source":["# print('Saving model for BEST loss - ', best_val_loss)\n","# savemodel = model.module if hasattr(model, 'module') else model\n","# torch.save(savemodel.state_dict(), MODEL_PATH)\n","# savemodel.config.to_json_file(CONFIG_PATH)\n","# tokenizer.save_vocabulary(MODEL_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5w03pomr21Xc"},"source":["!ls '$MODEL_DIR'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"drERJcpqF4O2"},"source":["# Analyse"]},{"cell_type":"code","metadata":{"id":"pGTkbHYrFPIj"},"source":["# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(loss_values, 'b-o', label=\"training loss\")\n","plt.plot(val_loss_values, 'r-o', label=\"validation loss\")\n","\n","# Label the plot.\n","plt.title(\"Learning curve\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","\n","plt.savefig(OUTPUT_DIR + \"/loss.png\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWlQEulT35ch"},"source":["!ls '$OUTPUT_DIR'"],"execution_count":null,"outputs":[]}]}